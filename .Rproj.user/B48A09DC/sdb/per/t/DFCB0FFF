{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Support Vector Machine\"\nauthor: Jingyu Bao\ndate: 2016-11-14\noutput: html_notebook\n---\n\n\nThe Class is y label.\n\n```{r}\nlibrary(caret)\n\ndata(segmentationData)\n\nsegmentationData %>% \n    head(10)\n\nset.seed(100)\ntrainIndex <- createDataPartition(segmentationData$Class, p = .8, \n                                  list = FALSE, \n                                  times = 1)\n\nsegTrain <- segmentationData[trainIndex,]\nsegTest <- segmentationData[-trainIndex,]\ntrainX <- segTrain[,4:61]\n\nset.seed(1000)\nfitControl <- trainControl(## 10-fold CV\n                           method = \"repeatedcv\",\n                           number = 10,\n                           ## repeated five times\n                           repeats = 5)\n\nsvmFit <- train(x = trainX, \n                y = segTrain$Class,\n                data = segTrain,\n                method = \"svmLinear\", \n                trControl = fitControl,\n                tuneLength = 15)\nsvmFit\n```\n\nPredict/Test\n```{r}\nsegPred <- predict(svmFit, segTest[,4:61])\n\nsegPred %>% \n    head(10)\n\nconfusionMatrix(data = segPred, reference = segTest$Class)\n\npostResample(pred = segPred, obs = segTest$Class)\n```\n\n\n\n\nFor Kappa statistic, from [here](http://stats.stackexchange.com/questions/82162/kappa-statistic-in-plain-english)\n\n> Kappa = (observed accuracy - expected accuracy)/(1 - expected accuracy)\n\n> There is not a standardized interpretation of the kappa statistic. According to Wikipedia (citing their paper), Landis and Koch considers 0-0.20 as slight, 0.21-0.40 as fair, 0.41-0.60 as moderate, 0.61-0.80 as substantial, and 0.81-1 as almost perfect. Fleiss considers kappas > 0.75 as excellent, 0.40-0.75 as fair to good, and < 0.40 as poor.\n\n\nVisualization\n\n```{r}\nlibrary(e1071)\ndata(cats, package = \"MASS\")\nm <- svm(Sex~., data = cats)\nplot(m, cats)\n\nsvmRadialFit <- train(Species ~ .,\n                data = iris, \n                method = \"svmRadial\", \n                metric = \"Kappa\",\n                control = trainControl(method = \"cv\"))\n\n\nplot(svmRadialFit, metric = svmRadialFit$metric)\n\nggplot(svmRadialFit) + theme_bw()\n```\n\n\n\n### Others\n\n\nexample from [here](https://www.r-bloggers.com/the-5th-tribe-support-vector-machines-and-caret/)\n\n```{r}\n## SUPPORT VECTOR MACHINE MODEL\n# First pass\nset.seed(1492)\n# Setup for cross validation\nctrl <- trainControl(method=\"repeatedcv\",   # 10fold cross validation\n                     repeats=2,\t\t    # do 2 repititions of cv\n                     summaryFunction=twoClassSummary,\t# Use AUC to pick the best model\n                     classProbs=TRUE)\n \n \n#Train and Tune the SVM\nsvm.tune <- train(x =trainX,\n                  y = segTrain$Class,\n                  method = \"svmRadial\",   # Radial kernel\n                  tuneLength = 9,\t\t\t\t\t# 9 values of the cost function\n                  preProc = c(\"center\",\"scale\"),  # Center and scale data\n                  metric = \"ROC\",\n                  trControl = ctrl)\nsvm.tune\n```\n\n\nAnother example from [here](http://machinelearningmastery.com/non-linear-regression-in-r/)\n\n```{r}\n# load the package\nlibrary(kernlab)\n# load data\ndata(longley)\n# fit model\nfit <- ksvm(Employed~., longley)\n# summarize the fit\nsummary(fit)\n# make predictions\npredictions <- predict(fit, longley)\n# summarize accuracy\nrmse <- mean((longley$Employed - predictions)^2)\nprint(rmse)\n```\n\n",
    "created" : 1479229639089.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3189018122",
    "id" : "DFCB0FFF",
    "lastKnownWriteTime" : 1479231953,
    "last_content_update" : 1479231953437,
    "path" : "C:/Users/zhong/Dropbox/Statistical Learning/Algorithms/svm/svm.Rmd",
    "project_path" : "svm/svm.Rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}