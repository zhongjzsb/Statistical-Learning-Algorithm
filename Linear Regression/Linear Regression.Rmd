---
title: "Linear Regression"
author: Jingyu Bao
date: 2016-11-15
output: html_notebook
---

[Linear Regression under big data](https://zhuanlan.zhihu.com/p/25312342?utm_medium=social&utm_source=ZHShareTargetIDMore)


```{r}
library(caret)
data(Sacramento)

Sacramento %>% 
    head(10)

set.seed(100)
trainIndex <- createDataPartition(Sacramento$price, p = .8, 
                                  list = FALSE, 
                                  times = 1)

sacTrain <- Sacramento[trainIndex,]
sacTest <- Sacramento[-trainIndex,]
trainX <- sacTrain[c('beds', 'sqft', 'baths', 'latitude', 'longitude')]

set.seed(1000)
fitControl <- trainControl(## 5-fold CV
                           method = "repeatedcv",
                           number = 5,
                           ## repeated two times
                           repeats = 2)


lmFit <- train(x = trainX, 
               y = sacTrain$price,
               method = "lm", 
               metric = "RMSE",
               tuneLength = 10,
               trControl = fitControl)

lmFit

lmFit <- train(price~. -price,
               data = sacTrain,
               method = "lm", 
               metric = "RMSE",
               tuneLength = 10,
               trControl = fitControl)

lmFit
```


## Ridge Regression
```{r}
head(sacTrain)
ridgeGrid <- expand.grid(fraction=c(1,0.1,0.01,0.001))

ridgeFit <- train(x = trainX[c('sqft', 'longitude', 'latitude')], 
               y = sacTrain$price,
               method = "ridge", 
               metric = "RMSE",
               # tuneGrid = ridgeGrid,
               tuneLength = 3)

plot(ridgeFit)

predict(ridgeFit$finalModel, type = 'coefficients')
ridgeFit$finalModel$beta.pure
coef(ridgeFit$finalModel, ridgeFit$finalModel$lambda)
```

The model can also be 'glmnet'.

Following examples are collected from [DataCamp](https://campus.datacamp.com/courses/preparing-for-machine-learning-interview-questions-in-r/)


```{r}
# Lasso regression: mdlLasso
mdlLasso <- train(PlayerValue ~ ., 
                  data = fifa19_scaled,
                  method = "lasso", tuneLength = 8)

# Plot lasso object
plot(mdlLasso)

# Get coefficients in every step: coefLasso
coefLasso <- predict(mdlLasso$finalModel, type='coef', mode='norm')$coefficients

# Get coefficients for top 5 and all variables
(coefs$LassoTop5 <- coefLasso[6,])
(coefs$LassoAll <- coefLasso[nrow(coefLasso),])
```


```{r}
# ElasticNet regression: mdlElasticNet
mdlElasticNet <- train(PlayerValue ~ ., data = fifa19_scaled,
                       method = "enet", tuneLength = 8)

# Plot elastic net object
plot(mdlElasticNet)

# Get elastic net coefficients: coefElasticNet
coefElasticNet <- predict(mdlElasticNet$finalModel, type='coef', mode='norm')$coefficients

coefElasticNet

# Get coefficients for top 5 and all variables
(coefs$ElasticNetTop5 <- coefElasticNet[6, ])
(coefs$ElasticNetAll <- coefElasticNet[nrow(coefElasticNet), ])
```